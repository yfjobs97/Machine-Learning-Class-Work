{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72c50938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'park_test.data' already there; not retrieving.\n",
      "\n",
      "File 'park_train.data' already there; not retrieving.\n",
      "\n",
      "File 'park_validation.data' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "!wget -nc https://personal.utdallas.edu/~yangxiao.lu/22SP_CS6375/park_test.data\n",
    "!wget -nc https://personal.utdallas.edu/~yangxiao.lu/22SP_CS6375/park_train.data\n",
    "!wget -nc https://personal.utdallas.edu/~yangxiao.lu/22SP_CS6375/park_validation.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "589da85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y dimention:  (78, 1)\n",
      "X dimnetion:  (78, 22)\n",
      "Y_Validation dimention:  (58, 1)\n",
      "X_Validation dimnetion:  (58, 22)\n",
      "Y_Test dimention:  (59, 1)\n",
      "X_Test dimnetion:  (59, 22)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "\n",
    "col_names = ['y','x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20','x21','x22']\n",
    "data =  pd.read_csv('park_train.data', sep=\",\" , names = col_names)\n",
    "Y = data['y'].values\n",
    "Y = Y.reshape(-1,1)\n",
    "print('Y dimention: ',Y.shape)\n",
    "X = data[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20','x21','x22']].values\n",
    "print('X dimnetion: ',X.shape)\n",
    "\n",
    "ValidationData =  pd.read_csv('park_validation.data', sep=\",\" , names = col_names)\n",
    "Y_Validation = ValidationData['y'].values\n",
    "Y_Validation = Y_Validation.reshape(-1,1)\n",
    "print('Y_Validation dimention: ',Y_Validation.shape)\n",
    "X_Validation = ValidationData[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20','x21','x22']].values\n",
    "print('X_Validation dimnetion: ',X_Validation.shape)\n",
    "\n",
    "TestData =  pd.read_csv('park_test.data', sep=\",\" , names = col_names)\n",
    "Y_Test = TestData['y'].values\n",
    "Y_Test = Y_Test.reshape(-1,1)\n",
    "print('Y_Test dimention: ',Y_Test.shape)\n",
    "X_Test = TestData[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20','x21','x22']].values\n",
    "print('X_Test dimnetion: ',X_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "347a1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part1 Accuracy:   0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Part1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "clf = LogisticRegression(penalty='none',dual=False,random_state=0, solver='saga').fit(X, Y)\n",
    "\n",
    "pred = clf.predict(X_Test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_Test, pred)\n",
    "print(\"Part1 Accuracy:   %0.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "350302e7",
   "metadata": {},
   "source": [
    "# Explain why in standard logistic regression, without any type of regularization, the weights may not converge (even though the predicted label for each data point effectively does) if the input data is linearly separable.\n",
    "    When performing log likelihood in the case where same sets of x yields different y, the slope never flats out. As a result, no maximum likelihood can be found, and MLE does not exist. Since the convergence of Logistic Regression require the existence of MLE, without so, convergence cannot be reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5619c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with C =  0.5  using validation data is:   0.810\n",
      "Accuracy with C =  0.75  using validation data is:   0.810\n",
      "Accuracy with C =  1.0  using validation data is:   0.845\n",
      "Accuracy with C =  1.25  using validation data is:   0.828\n",
      "Accuracy with C =  1.5  using validation data is:   0.862\n",
      "Accuracy with C =  1.75  using validation data is:   0.845\n",
      "Accuracy with C =  2.0  using validation data is:   0.845\n",
      "Part2: Accuracy with BestC =  1.5  using Test data is:   0.847\n",
      "Weight Vectors for l2: [[ 1.22534487e-02 -7.43742849e-03 -1.13207471e-02  6.67019730e-03\n",
      "   5.95805405e-05  7.66800238e-03  6.49891341e-03  2.29976403e-02\n",
      "   1.26574823e-01  1.22232574e+00  7.05140114e-02  7.57629809e-02\n",
      "   9.30684247e-02  2.11556566e-01 -1.40296849e-02  8.50919041e-02\n",
      "   4.31245236e-01  7.44586799e-01  1.07708781e+00  5.14515496e-01\n",
      "   2.10195918e+00  5.61646548e-01]]\n",
      "Variance of weights :  0.27423462\n"
     ]
    }
   ],
   "source": [
    "#Part2\n",
    "constants=[0.5,0.75,1.0,1.25,1.5,1.75,2.0]\n",
    "accuracy_old = 0.0\n",
    "bestC = constants[0]\n",
    "for c in constants:\n",
    "    clf = LogisticRegression(penalty='l2',C=c,dual=False,random_state=10, solver='liblinear').fit(X, Y.ravel())\n",
    "    pred = clf.predict(X_Validation)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(Y_Validation, pred)\n",
    "    print(\"Accuracy with C = \", c,\" using validation data is:   %0.3f\" % accuracy)\n",
    "    if accuracy > accuracy_old:\n",
    "        bestC = c\n",
    "    accuracy_old = accuracy\n",
    "clf = LogisticRegression(penalty='l2',C=bestC,dual=False,random_state=10, solver='liblinear').fit(X, Y.ravel())\n",
    "pred = clf.predict(X_Test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_Test, pred)\n",
    "print(\"Part2: Accuracy with BestC = \", bestC,\" using Test data is:   %0.3f\" % accuracy)\n",
    "print(\"Weight Vectors for l2:\", clf.coef_)\n",
    "print(\"Variance of weights : \", np.var(clf.coef_, dtype = np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd5f45e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with C =  0.5  using validation data is:   0.828\n",
      "Accuracy with C =  0.75  using validation data is:   0.862\n",
      "Accuracy with C =  1.0  using validation data is:   0.862\n",
      "Accuracy with C =  1.25  using validation data is:   0.862\n",
      "Accuracy with C =  1.5  using validation data is:   0.862\n",
      "Accuracy with C =  1.75  using validation data is:   0.862\n",
      "Accuracy with C =  2.0  using validation data is:   0.862\n",
      "Part3: Accuracy with BestC =  0.75  using Test data is:   0.831\n",
      "Weight Vectors for l1: [[ 2.91247519e-03 -7.10778401e-03 -8.92950512e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.10971567e-02\n",
      "   0.00000000e+00  0.00000000e+00  6.84901805e-01  0.00000000e+00\n",
      "   3.14464499e+00  0.00000000e+00]]\n",
      "Variance of weights :  0.44055635\n"
     ]
    }
   ],
   "source": [
    "#Part3\n",
    "constants=[0.5,0.75,1.0,1.25,1.5,1.75,2.0]\n",
    "accuracy_old = 0.0\n",
    "bestC = constants[0]\n",
    "for c in constants:\n",
    "    clf = LogisticRegression(penalty='l1',C=c,dual=False,random_state=10, solver='liblinear').fit(X, Y.ravel())\n",
    "    pred = clf.predict(X_Validation)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(Y_Validation, pred)\n",
    "    print(\"Accuracy with C = \", c,\" using validation data is:   %0.3f\" % accuracy)\n",
    "    if accuracy > accuracy_old:\n",
    "        bestC = c\n",
    "    accuracy_old = accuracy\n",
    "clf = LogisticRegression(penalty='l1',C=bestC,dual=False,random_state=10, solver='liblinear').fit(X, Y.ravel())\n",
    "pred = clf.predict(X_Test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_Test, pred)\n",
    "print(\"Part3: Accuracy with BestC = \", bestC,\" using Test data is:   %0.3f\" % accuracy)\n",
    "print(\"Weight Vectors for l1:\", clf.coef_)\n",
    "print(\"Variance of weights : \", np.var(clf.coef_, dtype = np.float32)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd08fcb",
   "metadata": {},
   "source": [
    "Part 4: L1 produces sparser weight vectors, as it has higher variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
